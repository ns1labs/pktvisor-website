{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Open source, network observability agent for analysis at the edge \u00b6 Get Started with pktvisor What is pktvisor? \u00b6 pktvisor (pronounced \"packet visor\") is an observability agent for analyzing high volume, information dense network data streams and extracting actionable insights directly from the edge . How is pktvisor different? \u00b6 It is a resource-efficient agent built from the ground up to be modular , dynamically controlled in real time and produce \"small data\" metric and log output. Why pktvisor? \u00b6 Metric output can be visualized and actioned on-node as well as centrally collected into modern observability stacks. What questions does pktvisor answer? \u00b6 pktvisor uses streaming algorithms to analyze in real time , providing metrics which let you answer questions such as: What are the rates and frequent items across common network traffic dimensions? How many unique IP addresses (cardinality) have we seen in the last minute? What are the percentiles of DNS transaction times? What is the histogram of response payload sizes? What is still querying that DNS record that was deleted? From what ASN and Geo regions is traffic coming? Is this traffic spike malicious or legitimate? Is this a random label attack? Is it widely distributed? IPv4? UDP? How can I centrally control and collect pktvisor metrics? \u00b6 Although pktvisor can be used stand-alone, it is designed to be run at scale as part of the Observability Platform . Backed by NS1 \u00b6 pktvisor was born at NS1 Labs , where we're committed to making open source, dynamic edge observability a reality .","title":"Home"},{"location":"#open-source-network-observability-agent-for-analysis-at-the-edge","text":"Get Started with pktvisor","title":"Open source, network observability agent for analysis at the edge"},{"location":"#what-is-pktvisor","text":"pktvisor (pronounced \"packet visor\") is an observability agent for analyzing high volume, information dense network data streams and extracting actionable insights directly from the edge .","title":"What is pktvisor?"},{"location":"#how-is-pktvisor-different","text":"It is a resource-efficient agent built from the ground up to be modular , dynamically controlled in real time and produce \"small data\" metric and log output.","title":"How is pktvisor different?"},{"location":"#why-pktvisor","text":"Metric output can be visualized and actioned on-node as well as centrally collected into modern observability stacks.","title":"Why pktvisor?"},{"location":"#what-questions-does-pktvisor-answer","text":"pktvisor uses streaming algorithms to analyze in real time , providing metrics which let you answer questions such as: What are the rates and frequent items across common network traffic dimensions? How many unique IP addresses (cardinality) have we seen in the last minute? What are the percentiles of DNS transaction times? What is the histogram of response payload sizes? What is still querying that DNS record that was deleted? From what ASN and Geo regions is traffic coming? Is this traffic spike malicious or legitimate? Is this a random label attack? Is it widely distributed? IPv4? UDP?","title":"What questions does pktvisor answer?"},{"location":"#how-can-i-centrally-control-and-collect-pktvisor-metrics","text":"Although pktvisor can be used stand-alone, it is designed to be run at scale as part of the Observability Platform .","title":"How can I centrally control and collect pktvisor metrics?"},{"location":"#backed-by-ns1","text":"pktvisor was born at NS1 Labs , where we're committed to making open source, dynamic edge observability a reality .","title":"Backed by NS1"},{"location":"about/","text":"The story \u00b6 Born at NS1 Labs , pktvisor has its origins in observability of critical internet infrastructure in support of DDoS protection, traffic engineering, and ongoing operations. NS1 created pktvisor to address its own need for more visibility across its global anycast network. As this tool will benefit other organizations leveraging distributed edge architectures, NS1 made it open source and invites the developer community to help drive future updates and innovation. By efficiently summarizing and collecting key metrics at all of your edge locations, you gain a deep understanding of traffic patterns in real time, enabling rich visualization and fast automation which further increase resiliency and performance. pktvisor + Orb \u00b6 The resource-efficient pktvisor agent performs edge analysis on network data streams. Via the open source Orb , you can decide what data to extract from which agents. This combination allows you to: Adjust analysis and collection parameters dynamically across the entire fleet via a powerful control plane Perform centralized fleet management, allowing you to configure heartbeats, tagging, and grouping for each of the pktvisor agents Orchestrate data-set policies that specify the type of data to extract from each agent In terms of metrics, pktvisor has built-in support for DNS, DHCP, and L2/L3 network data via packet capture , dnstap , sFlow , NetFlow / IPFIX , among other input methods and is easily extendable for other protocols. For a complete list of metrics currently collected by pktvisor , look here . To view a Grafana dashboard for visualizing pktvisor Prometheus metrics , look here .","title":"About"},{"location":"about/#the-story","text":"Born at NS1 Labs , pktvisor has its origins in observability of critical internet infrastructure in support of DDoS protection, traffic engineering, and ongoing operations. NS1 created pktvisor to address its own need for more visibility across its global anycast network. As this tool will benefit other organizations leveraging distributed edge architectures, NS1 made it open source and invites the developer community to help drive future updates and innovation. By efficiently summarizing and collecting key metrics at all of your edge locations, you gain a deep understanding of traffic patterns in real time, enabling rich visualization and fast automation which further increase resiliency and performance.","title":"The story"},{"location":"about/#pktvisor-orb","text":"The resource-efficient pktvisor agent performs edge analysis on network data streams. Via the open source Orb , you can decide what data to extract from which agents. This combination allows you to: Adjust analysis and collection parameters dynamically across the entire fleet via a powerful control plane Perform centralized fleet management, allowing you to configure heartbeats, tagging, and grouping for each of the pktvisor agents Orchestrate data-set policies that specify the type of data to extract from each agent In terms of metrics, pktvisor has built-in support for DNS, DHCP, and L2/L3 network data via packet capture , dnstap , sFlow , NetFlow / IPFIX , among other input methods and is easily extendable for other protocols. For a complete list of metrics currently collected by pktvisor , look here . To view a Grafana dashboard for visualizing pktvisor Prometheus metrics , look here .","title":"pktvisor + Orb"},{"location":"contact/","text":"Contribute \u00b6 pktvisor is an open source project founded at NS1 Labs . Work with us on GitHub and star the project to show your interest. Star on GitHub Contact \u00b6 We want to hear about your use cases, feature requests, and other feedback. Please open Pull Requests against the develop branch. If you are considering a larger contribution, please contact us to discuss your design via the following options: Sign up to get pktvisor and Orb updates File an issue See existing issues Start a discussion Join us on Slack Send mail to info@pktvisor.dev See the NS1 Contribution Guidelines for more information. Build \u00b6 The main code base is written in clean, modern C++. The pktvisor-cli command-line interface is written in Go. The build system requires CMake and the Conan package manager system. pktvisor adheres to semantic versioning . pktvisor is developed and tested on Linux and OSX. A Windows port is in progress. Both x86_64 and ARM architectures are known to function. Dependencies \u00b6 Conan C++ package manager CMake >= 3.13 ( cmake ) C++ compiler supporting C++17 For the list of packages included by conan, see conanfile.txt . Building \u00b6 The general build steps are: # clone the repository git clone https://github.com/ns1labs/pktvisor.git cd pktvisor mkdir build && cd build # configure and handle dependencies cmake -DCMAKE_BUILD_TYPE = Release .. # build and run tests make all test # the binaries will be in the build/bin directory bin/pktvisord --help As development environments can vary widely, please see the Dockerfile and Continuous Integration build file for reference. Explore \u00b6 Articles \u00b6 Orb Data Sheet: Actionable Edge Observability Using DNS to Minimize Cyber Threat Exposure Deep Network Traffic Observability with Pktvisor and Prometheus Q4 2021 Update on NS1 Labs: pktvisor, Orb, NetBox Cloud Extracting the Signal: Rethinking Network Observability A Wave of Open Source Innovation at NS1 Labs with Orb and NetBox NS1 Launches Innovation Lab to Solve Challenges in Modern Application Delivery and Edge Networking NS1 Releases Open Source Tool for Network Visibility, Announces Support for DNS over HTTPS to Flamethrower Conference Presentations \u00b6 PromCon North America: Deep Network Traffic Observability , 2021 - Recording , Slides ICANN DNS Symposium , 2021 - Recording , Slides DNS-OARC , 2020 - Recording (first talk), Slides O'Reilly Velocity San Jose , 2019 - Recording , Slides","title":"Community"},{"location":"contact/#contribute","text":"pktvisor is an open source project founded at NS1 Labs . Work with us on GitHub and star the project to show your interest. Star on GitHub","title":"Contribute"},{"location":"contact/#contact","text":"We want to hear about your use cases, feature requests, and other feedback. Please open Pull Requests against the develop branch. If you are considering a larger contribution, please contact us to discuss your design via the following options: Sign up to get pktvisor and Orb updates File an issue See existing issues Start a discussion Join us on Slack Send mail to info@pktvisor.dev See the NS1 Contribution Guidelines for more information.","title":"Contact"},{"location":"contact/#build","text":"The main code base is written in clean, modern C++. The pktvisor-cli command-line interface is written in Go. The build system requires CMake and the Conan package manager system. pktvisor adheres to semantic versioning . pktvisor is developed and tested on Linux and OSX. A Windows port is in progress. Both x86_64 and ARM architectures are known to function.","title":"Build"},{"location":"contact/#dependencies","text":"Conan C++ package manager CMake >= 3.13 ( cmake ) C++ compiler supporting C++17 For the list of packages included by conan, see conanfile.txt .","title":"Dependencies"},{"location":"contact/#building","text":"The general build steps are: # clone the repository git clone https://github.com/ns1labs/pktvisor.git cd pktvisor mkdir build && cd build # configure and handle dependencies cmake -DCMAKE_BUILD_TYPE = Release .. # build and run tests make all test # the binaries will be in the build/bin directory bin/pktvisord --help As development environments can vary widely, please see the Dockerfile and Continuous Integration build file for reference.","title":"Building"},{"location":"contact/#explore","text":"","title":"Explore"},{"location":"contact/#articles","text":"Orb Data Sheet: Actionable Edge Observability Using DNS to Minimize Cyber Threat Exposure Deep Network Traffic Observability with Pktvisor and Prometheus Q4 2021 Update on NS1 Labs: pktvisor, Orb, NetBox Cloud Extracting the Signal: Rethinking Network Observability A Wave of Open Source Innovation at NS1 Labs with Orb and NetBox NS1 Launches Innovation Lab to Solve Challenges in Modern Application Delivery and Edge Networking NS1 Releases Open Source Tool for Network Visibility, Announces Support for DNS over HTTPS to Flamethrower","title":"Articles"},{"location":"contact/#conference-presentations","text":"PromCon North America: Deep Network Traffic Observability , 2021 - Recording , Slides ICANN DNS Symposium , 2021 - Recording , Slides DNS-OARC , 2020 - Recording (first talk), Slides O'Reilly Velocity San Jose , 2019 - Recording , Slides","title":"Conference Presentations"},{"location":"docs/","text":"Documentation \u00b6 Agent Usage \u00b6 A collector agent should be installed on each node to be monitored. Current command-line options are described with: docker run --rm ns1labs/pktvisor pktvisord --help or ./pktvisor-x86_64.AppImage pktvisord --help Usage: pktvisord [options] [IFACE] pktvisord (-h | --help) pktvisord --version pktvisord summarizes data streams and exposes a REST API control plane for configuration and metrics. pktvisord operation is configured via Taps and Collection Policies. Taps abstract the process of \"tapping into\" input streams with templated configuration while Policies use Taps to instantiate and configure Input and Stream Handlers to analyze and summarize stream data, which is then made available for collection via REST API. Taps and Collection Policies may be created by passing the appropriate YAML configuration file to --config, and/or by enabling the admin REST API with --admin-api and using the appropriate endpoints. Alternatively, for simple use cases you may specify IFACE, which is either a network interface or an IP address (4 or 6). If this is specified, \"default\" Tap and Collection Policies will be created with a \"pcap\" input stream on the specified interfaced, along with the built in \"net\", \"dns\", and \"pcap\" Stream Handler modules attached. Note that this feature may be deprecated in the future. For more documentation, see https://pktvisor.dev Base Options: -d Daemonize; fork and continue running in the background [default: false] -h --help Show this screen -v Verbose log output --no-track Don't send lightweight, anonymous usage metrics --version Show version Web Server Options: -l HOST Run web server on the given host or IP [default: localhost] -p PORT Run web server on the given port [default: 10853] --tls Enable TLS on the web server --tls-cert FILE Use given TLS cert. Required if --tls is enabled. --tls-key FILE Use given TLS private key. Required if --tls is enabled. --admin-api Enable admin REST API giving complete control plane functionality [default: false] When not specified, the exposed API is read-only access to module status and metrics. When specified, write access is enabled for all modules. Geo Options: --geo-city FILE GeoLite2 City database to use for IP to Geo mapping --geo-asn FILE GeoLite2 ASN database to use for IP to ASN mapping Configuration: --config FILE Use specified YAML configuration to configure options, Taps, and Collection Policies Please see https://pktvisor.dev for more information Modules: --module-list List all modules which have been loaded (builtin and dynamic). --module-dir DIR Set module load path. All modules in this directory will be loaded. Logging Options: --log-file FILE Log to the given output file name --syslog Log to syslog Prometheus Options: --prometheus Ignored, Prometheus output always enabled (left for backwards compatibility) --prom-instance ID Optionally set the 'instance' label to given ID Handler Module Defaults: --max-deep-sample N Never deep sample more than N% of streams (an int between 0 and 100) [default: 100] --periods P Hold this many 60 second time periods of history in memory [default: 5] pcap Input Module Options: (applicable to default policy when IFACE is specified only) -b BPF Filter packets using the given tcpdump compatible filter expression. Example: \"port 53\" -H HOSTSPEC Specify subnets (comma separated) to consider HOST, in CIDR form. In live capture this /may/ be detected automatically from capture device but /must/ be specified for pcaps. Example: \"10.0.1.0/24,10.0.2.1/32,2001:db8::/64\" Specifying this for live capture will append to any automatic detection. Configuration File Usage \u00b6 Configure pktvisord at startup by YAML configuration file with the --config option. The configuration file can configure all options available on the command line and define Policies and Taps . All sections are optional. Note that Policies and Taps may also be maintained in real-time via REST API . version: \"1.0\" visor: # optionally define global configuration (see command line options) config: verbose: true # optionally define taps taps: default_pcap: input_type: pcap config: iface: eth0 filter: bpf: \"port 53\" unix_dnstap: input_type: dnstap config: socket: \"/tmp/dnstap.sock\" tcp_dnstap: input_type: dnstap config: tcp: \"127.0.0.1:53053\" # optionally define policies policies: mysocket: kind: collection input: tap: unix_dnstap input_type: dnstap handlers: modules: default_net: type: net default_dns: type: dns config: only_qname_suffix: - \".google.com\" - \".ns1.com\" mytcp: kind: collection input: tap: tcp_dnstap input_type: dnstap handlers: modules: default_net: type: net default_dns: type: dns If running in a Docker container, you must mount the configuration file into the container. For example, if the configuration file is on the host at /local/pktvisor/agent.yaml , you can mount it into the container and use it with this command: docker run -v /local/pktvisor:/usr/local/pktvisor/ --net=host ns1labs/pktvisor pktvisord --config /usr/local/pktvisor/agent.yaml --admin-api Command-Line UI Usage \u00b6 The command-line UI ( pktvisor-cli ) connects directly to a pktvisord agent to visualize the real-time stream summarization, which is by default a sliding 5-minute time window. It can also connect to an agent running on a remote host. docker run --rm ns1labs/pktvisor pktvisor-cli -h ./pktvisor-x86_64.AppImage pktvisor-cli -h Usage: pktvisor-cli [-p PORT] [-H HOST] pktvisor-cli -h pktvisor-cli --version Options: -p PORT Query pktvisord metrics webserver on the given port [default: 10853] -H HOST Query pktvisord metrics webserver on the given host [default: localhost] -P POLICY pktvisor policy to query [default: default] --tls Use TLS to communicate with pktvisord metrics webserver --tls-noverify Do not verify TLS certificate -h Show this screen --version Show client version File Analysis (pcap and dnstap) \u00b6 pktvisor-reader is a tool that can statically analyze prerecorded packet capture and dnstap files. pcap files can come from many sources, the most famous of which is tcpdump . dnstap files can be generated from most DNS server software that support dnstap logging, either directly or using a tool such as golang-dnstap . Both take many of the same options, and do all of the same analysis, as pktvisord for live capture. pcap files may include Flow capture data. docker run --rm ns1labs/pktvisor pktvisor-reader --help ./pktvisor-x86_64.AppImage pktvisor-reader --help Usage: pktvisor-reader [options] FILE pktvisor-reader (-h | --help) pktvisor-reader --version Summarize a network (pcap, dnstap) file. The result will be written to stdout in JSON format, while console logs will be printed to stderr. Options: -i INPUT Input type (pcap|dnstap|sflow|netflow). If not set, default is pcap input --max-deep-sample N Never deep sample more than N% of streams (an int between 0 and 100) [default: 100] --periods P Hold this many 60 second time periods of history in memory. Use 1 to summarize all data. [default: 5] -h --help Show this screen --version Show version -v Verbose log output -b BPF Filter packets using the given BPF string --geo-city FILE GeoLite2 City database to use for IP to Geo mapping (if enabled) --geo-asn FILE GeoLite2 ASN database to use for IP to ASN mapping (if enabled) -H HOSTSPEC Specify subnets (comma separated) to consider HOST, in CIDR form. In live capture this /may/ be detected automatically from capture device but /must/ be specified for pcaps. Example: \"10.0.1.0/24,10.0.2.1/32,2001:db8::/64\" Specifying this for live capture will append to any automatic detection. You can use the Docker container by passing in a volume referencing the directory containing the pcap file. The standard output will contain the JSON summarization output, which you can capture or pipe into other tools, for example: $ docker run --rm -v /pktvisor/src/tests/fixtures:/pcaps ns1labs/pktvisor pktvisor-reader /pcaps/dns_ipv4_udp.pcap | jq . [2021-03-11 18:45:04.572] [pktvisor] [info] Load input plugin: PcapInputModulePlugin dev.visor.module.input/1.0 [2021-03-11 18:45:04.573] [pktvisor] [info] Load handler plugin: DnsHandler dev.visor.module.handler/1.0 [2021-03-11 18:45:04.573] [pktvisor] [info] Load handler plugin: NetHandler dev.visor.module.handler/1.0 ... processed 140 packets { \"5m\": { \"dns\": { \"cardinality\": { \"qname\": 70 }, \"period\": { \"length\": 6, \"start_ts\": 1567706414 }, \"top_nxdomain\": [], \"top_qname2\": [ { \"estimate\": 140, \"name\": \".test.com\" } ], ... The AppImage can access local files as any normal binary: $ ./pktvisor-x86_64.AppImage pktvisor-reader /pcaps/dns_ipv4_udp.pcap | jq . [2021-03-11 18:45:04.572] [pktvisor] [info] Load input plugin: PcapInputModulePlugin dev.visor.module.input/1.0 [2021-03-11 18:45:04.573] [pktvisor] [info] Load handler plugin: DnsHandler dev.visor.module.handler/1.0 [2021-03-11 18:45:04.573] [pktvisor] [info] Load handler plugin: NetHandler dev.visor.module.handler/1.0 ... processed 140 packets { \"5m\": { \"dns\": { \"cardinality\": { \"qname\": 70 }, \"period\": { \"length\": 6, \"start_ts\": 1567706414 }, \"top_nxdomain\": [], \"top_qname2\": [ { \"estimate\": 140, \"name\": \".test.com\" } ], ... Metrics Collection \u00b6 Metrics from the REST API \u00b6 The metrics are available from the agent in JSON format via the REST API . For most use cases, you will want to collect the most recent full 1-minute bucket: curl localhost:10853/api/v1/metrics/bucket/1 This can be done with tools like telegraf and the standard HTTP plugin . Example telegraf config snippet for the default policy: [inputs] [[inputs.http]] urls = [ \"http://127.0.0.1:10853/api/v1/metrics/bucket/1\",] interval = \"60s\" data_format = \"json\" json_query = \"1m\" json_time_key = \"period_start_ts\" json_time_format = \"unix\" json_string_fields = [ \"dns_*\", \"packets_*\", \"dhcp_*\", \"pcap_*\", ] [inputs.http.tags] t = \"pktvisor\" interval = \"60\" Prometheus Metrics \u00b6 pktvisord has native Prometheus support. The default policy metrics are available for collection at the standard /metrics endpoint, or use /api/v1/policies/__all/metrics/prometheus to collect metrics from all policies. $ ./pktvisor-x86_64.AppImage pktvisord -d eth0 $ curl localhost:10853/metrics # HELP dns_wire_packets_udp Total DNS wire packets received over UDP (ingress and egress) # TYPE dns_wire_packets_udp gauge dns_wire_packets_udp { instance = \"node\" ,policy = \"default\" } 28 # HELP dns_rates_total Rate of all DNS wire packets (combined ingress and egress) per second # TYPE dns_rates_total summary dns_rates_total { instance = \"node\" ,policy = \"default\" ,quantile = \"0.5\" } 0 dns_rates_total { instance = \"node\" ,policy = \"default\" ,quantile = \"0.9\" } 4 dns_rates_total { instance = \"node\" ,policy = \"default\" ,quantile = \"0.95\" } 4 ... You can set the instance label by passing --prom-instance ID . If you are interested in centralized collection using remote write , including to cloud providers, there is a Docker image available to make this easy. See centralized_collection/prometheus for more information. Also check out Orb's site for information on connecting pktvisor agents to the Orb observability platform. REST API \u00b6 REST API documentation is available in OpenAPI Format . Please note the administration control plane API ( --admin-api ) is currently undergoing heavy iteration thus not yet documented. If you have a use case that requires the administration API, please contact us to discuss. Advanced Agent Example \u00b6 To start the collector agent from Docker with MaxmindDB GeoIP/GeoASN support using the Host option to identify ingress and egress traffic: docker run --rm --net=host -d \\ --mount type=bind,source=/opt/geo,target=/geo \\ ns1labs/pktvisor pktvisord \\ --geo-city /geo/GeoIP2-City.mmdb \\ --geo-asn /geo/GeoIP2-ISP.mmdb \\ -H 192.168.0.54/32,127.0.0.1/32 \\ eth0 The same command with AppImage and logging to syslog: ./pktvisor-x86_64.AppImage pktvisord -d --syslog \\ --geo-city /geo/GeoIP2-City.mmdb \\ --geo-asn /geo/GeoIP2-ISP.mmdb \\ -H 192.168.0.54/32,127.0.0.1/32 \\ eth0 Further Documentation \u00b6 We recognize the value of first-class documentation. We are working on further documentation including expanded and updated REST API documentation, internal documentation for developers of input and handler modules (and those who want to contribute to pktvisor), and a user manual. Please contact us if you have any questions on installation, use, or development.","title":"Documentation"},{"location":"docs/#documentation","text":"","title":"Documentation"},{"location":"docs/#agent-usage","text":"A collector agent should be installed on each node to be monitored. Current command-line options are described with: docker run --rm ns1labs/pktvisor pktvisord --help or ./pktvisor-x86_64.AppImage pktvisord --help Usage: pktvisord [options] [IFACE] pktvisord (-h | --help) pktvisord --version pktvisord summarizes data streams and exposes a REST API control plane for configuration and metrics. pktvisord operation is configured via Taps and Collection Policies. Taps abstract the process of \"tapping into\" input streams with templated configuration while Policies use Taps to instantiate and configure Input and Stream Handlers to analyze and summarize stream data, which is then made available for collection via REST API. Taps and Collection Policies may be created by passing the appropriate YAML configuration file to --config, and/or by enabling the admin REST API with --admin-api and using the appropriate endpoints. Alternatively, for simple use cases you may specify IFACE, which is either a network interface or an IP address (4 or 6). If this is specified, \"default\" Tap and Collection Policies will be created with a \"pcap\" input stream on the specified interfaced, along with the built in \"net\", \"dns\", and \"pcap\" Stream Handler modules attached. Note that this feature may be deprecated in the future. For more documentation, see https://pktvisor.dev Base Options: -d Daemonize; fork and continue running in the background [default: false] -h --help Show this screen -v Verbose log output --no-track Don't send lightweight, anonymous usage metrics --version Show version Web Server Options: -l HOST Run web server on the given host or IP [default: localhost] -p PORT Run web server on the given port [default: 10853] --tls Enable TLS on the web server --tls-cert FILE Use given TLS cert. Required if --tls is enabled. --tls-key FILE Use given TLS private key. Required if --tls is enabled. --admin-api Enable admin REST API giving complete control plane functionality [default: false] When not specified, the exposed API is read-only access to module status and metrics. When specified, write access is enabled for all modules. Geo Options: --geo-city FILE GeoLite2 City database to use for IP to Geo mapping --geo-asn FILE GeoLite2 ASN database to use for IP to ASN mapping Configuration: --config FILE Use specified YAML configuration to configure options, Taps, and Collection Policies Please see https://pktvisor.dev for more information Modules: --module-list List all modules which have been loaded (builtin and dynamic). --module-dir DIR Set module load path. All modules in this directory will be loaded. Logging Options: --log-file FILE Log to the given output file name --syslog Log to syslog Prometheus Options: --prometheus Ignored, Prometheus output always enabled (left for backwards compatibility) --prom-instance ID Optionally set the 'instance' label to given ID Handler Module Defaults: --max-deep-sample N Never deep sample more than N% of streams (an int between 0 and 100) [default: 100] --periods P Hold this many 60 second time periods of history in memory [default: 5] pcap Input Module Options: (applicable to default policy when IFACE is specified only) -b BPF Filter packets using the given tcpdump compatible filter expression. Example: \"port 53\" -H HOSTSPEC Specify subnets (comma separated) to consider HOST, in CIDR form. In live capture this /may/ be detected automatically from capture device but /must/ be specified for pcaps. Example: \"10.0.1.0/24,10.0.2.1/32,2001:db8::/64\" Specifying this for live capture will append to any automatic detection.","title":"Agent Usage"},{"location":"docs/#configuration-file-usage","text":"Configure pktvisord at startup by YAML configuration file with the --config option. The configuration file can configure all options available on the command line and define Policies and Taps . All sections are optional. Note that Policies and Taps may also be maintained in real-time via REST API . version: \"1.0\" visor: # optionally define global configuration (see command line options) config: verbose: true # optionally define taps taps: default_pcap: input_type: pcap config: iface: eth0 filter: bpf: \"port 53\" unix_dnstap: input_type: dnstap config: socket: \"/tmp/dnstap.sock\" tcp_dnstap: input_type: dnstap config: tcp: \"127.0.0.1:53053\" # optionally define policies policies: mysocket: kind: collection input: tap: unix_dnstap input_type: dnstap handlers: modules: default_net: type: net default_dns: type: dns config: only_qname_suffix: - \".google.com\" - \".ns1.com\" mytcp: kind: collection input: tap: tcp_dnstap input_type: dnstap handlers: modules: default_net: type: net default_dns: type: dns If running in a Docker container, you must mount the configuration file into the container. For example, if the configuration file is on the host at /local/pktvisor/agent.yaml , you can mount it into the container and use it with this command: docker run -v /local/pktvisor:/usr/local/pktvisor/ --net=host ns1labs/pktvisor pktvisord --config /usr/local/pktvisor/agent.yaml --admin-api","title":"Configuration File Usage"},{"location":"docs/#command-line-ui-usage","text":"The command-line UI ( pktvisor-cli ) connects directly to a pktvisord agent to visualize the real-time stream summarization, which is by default a sliding 5-minute time window. It can also connect to an agent running on a remote host. docker run --rm ns1labs/pktvisor pktvisor-cli -h ./pktvisor-x86_64.AppImage pktvisor-cli -h Usage: pktvisor-cli [-p PORT] [-H HOST] pktvisor-cli -h pktvisor-cli --version Options: -p PORT Query pktvisord metrics webserver on the given port [default: 10853] -H HOST Query pktvisord metrics webserver on the given host [default: localhost] -P POLICY pktvisor policy to query [default: default] --tls Use TLS to communicate with pktvisord metrics webserver --tls-noverify Do not verify TLS certificate -h Show this screen --version Show client version","title":"Command-Line UI Usage"},{"location":"docs/#file-analysis-pcap-and-dnstap","text":"pktvisor-reader is a tool that can statically analyze prerecorded packet capture and dnstap files. pcap files can come from many sources, the most famous of which is tcpdump . dnstap files can be generated from most DNS server software that support dnstap logging, either directly or using a tool such as golang-dnstap . Both take many of the same options, and do all of the same analysis, as pktvisord for live capture. pcap files may include Flow capture data. docker run --rm ns1labs/pktvisor pktvisor-reader --help ./pktvisor-x86_64.AppImage pktvisor-reader --help Usage: pktvisor-reader [options] FILE pktvisor-reader (-h | --help) pktvisor-reader --version Summarize a network (pcap, dnstap) file. The result will be written to stdout in JSON format, while console logs will be printed to stderr. Options: -i INPUT Input type (pcap|dnstap|sflow|netflow). If not set, default is pcap input --max-deep-sample N Never deep sample more than N% of streams (an int between 0 and 100) [default: 100] --periods P Hold this many 60 second time periods of history in memory. Use 1 to summarize all data. [default: 5] -h --help Show this screen --version Show version -v Verbose log output -b BPF Filter packets using the given BPF string --geo-city FILE GeoLite2 City database to use for IP to Geo mapping (if enabled) --geo-asn FILE GeoLite2 ASN database to use for IP to ASN mapping (if enabled) -H HOSTSPEC Specify subnets (comma separated) to consider HOST, in CIDR form. In live capture this /may/ be detected automatically from capture device but /must/ be specified for pcaps. Example: \"10.0.1.0/24,10.0.2.1/32,2001:db8::/64\" Specifying this for live capture will append to any automatic detection. You can use the Docker container by passing in a volume referencing the directory containing the pcap file. The standard output will contain the JSON summarization output, which you can capture or pipe into other tools, for example: $ docker run --rm -v /pktvisor/src/tests/fixtures:/pcaps ns1labs/pktvisor pktvisor-reader /pcaps/dns_ipv4_udp.pcap | jq . [2021-03-11 18:45:04.572] [pktvisor] [info] Load input plugin: PcapInputModulePlugin dev.visor.module.input/1.0 [2021-03-11 18:45:04.573] [pktvisor] [info] Load handler plugin: DnsHandler dev.visor.module.handler/1.0 [2021-03-11 18:45:04.573] [pktvisor] [info] Load handler plugin: NetHandler dev.visor.module.handler/1.0 ... processed 140 packets { \"5m\": { \"dns\": { \"cardinality\": { \"qname\": 70 }, \"period\": { \"length\": 6, \"start_ts\": 1567706414 }, \"top_nxdomain\": [], \"top_qname2\": [ { \"estimate\": 140, \"name\": \".test.com\" } ], ... The AppImage can access local files as any normal binary: $ ./pktvisor-x86_64.AppImage pktvisor-reader /pcaps/dns_ipv4_udp.pcap | jq . [2021-03-11 18:45:04.572] [pktvisor] [info] Load input plugin: PcapInputModulePlugin dev.visor.module.input/1.0 [2021-03-11 18:45:04.573] [pktvisor] [info] Load handler plugin: DnsHandler dev.visor.module.handler/1.0 [2021-03-11 18:45:04.573] [pktvisor] [info] Load handler plugin: NetHandler dev.visor.module.handler/1.0 ... processed 140 packets { \"5m\": { \"dns\": { \"cardinality\": { \"qname\": 70 }, \"period\": { \"length\": 6, \"start_ts\": 1567706414 }, \"top_nxdomain\": [], \"top_qname2\": [ { \"estimate\": 140, \"name\": \".test.com\" } ], ...","title":"File Analysis (pcap and dnstap)"},{"location":"docs/#metrics-collection","text":"","title":"Metrics Collection"},{"location":"docs/#metrics-from-the-rest-api","text":"The metrics are available from the agent in JSON format via the REST API . For most use cases, you will want to collect the most recent full 1-minute bucket: curl localhost:10853/api/v1/metrics/bucket/1 This can be done with tools like telegraf and the standard HTTP plugin . Example telegraf config snippet for the default policy: [inputs] [[inputs.http]] urls = [ \"http://127.0.0.1:10853/api/v1/metrics/bucket/1\",] interval = \"60s\" data_format = \"json\" json_query = \"1m\" json_time_key = \"period_start_ts\" json_time_format = \"unix\" json_string_fields = [ \"dns_*\", \"packets_*\", \"dhcp_*\", \"pcap_*\", ] [inputs.http.tags] t = \"pktvisor\" interval = \"60\"","title":"Metrics from the REST API"},{"location":"docs/#prometheus-metrics","text":"pktvisord has native Prometheus support. The default policy metrics are available for collection at the standard /metrics endpoint, or use /api/v1/policies/__all/metrics/prometheus to collect metrics from all policies. $ ./pktvisor-x86_64.AppImage pktvisord -d eth0 $ curl localhost:10853/metrics # HELP dns_wire_packets_udp Total DNS wire packets received over UDP (ingress and egress) # TYPE dns_wire_packets_udp gauge dns_wire_packets_udp { instance = \"node\" ,policy = \"default\" } 28 # HELP dns_rates_total Rate of all DNS wire packets (combined ingress and egress) per second # TYPE dns_rates_total summary dns_rates_total { instance = \"node\" ,policy = \"default\" ,quantile = \"0.5\" } 0 dns_rates_total { instance = \"node\" ,policy = \"default\" ,quantile = \"0.9\" } 4 dns_rates_total { instance = \"node\" ,policy = \"default\" ,quantile = \"0.95\" } 4 ... You can set the instance label by passing --prom-instance ID . If you are interested in centralized collection using remote write , including to cloud providers, there is a Docker image available to make this easy. See centralized_collection/prometheus for more information. Also check out Orb's site for information on connecting pktvisor agents to the Orb observability platform.","title":"Prometheus Metrics"},{"location":"docs/#rest-api","text":"REST API documentation is available in OpenAPI Format . Please note the administration control plane API ( --admin-api ) is currently undergoing heavy iteration thus not yet documented. If you have a use case that requires the administration API, please contact us to discuss.","title":"REST API"},{"location":"docs/#advanced-agent-example","text":"To start the collector agent from Docker with MaxmindDB GeoIP/GeoASN support using the Host option to identify ingress and egress traffic: docker run --rm --net=host -d \\ --mount type=bind,source=/opt/geo,target=/geo \\ ns1labs/pktvisor pktvisord \\ --geo-city /geo/GeoIP2-City.mmdb \\ --geo-asn /geo/GeoIP2-ISP.mmdb \\ -H 192.168.0.54/32,127.0.0.1/32 \\ eth0 The same command with AppImage and logging to syslog: ./pktvisor-x86_64.AppImage pktvisord -d --syslog \\ --geo-city /geo/GeoIP2-City.mmdb \\ --geo-asn /geo/GeoIP2-ISP.mmdb \\ -H 192.168.0.54/32,127.0.0.1/32 \\ eth0","title":"Advanced Agent Example"},{"location":"docs/#further-documentation","text":"We recognize the value of first-class documentation. We are working on further documentation including expanded and updated REST API documentation, internal documentation for developers of input and handler modules (and those who want to contribute to pktvisor), and a user manual. Please contact us if you have any questions on installation, use, or development.","title":"Further Documentation"},{"location":"install/","text":"Installation \u00b6 Docker \u00b6 Get started quickly with pktvisor via the public Docker image . The image contains the collector agent ( pktvisord ), the command-line UI ( pktvisor-cli ), and the pcap and dnstap file analyzer ( pktvisor-reader ). You will specify which tool to operate when running the container. Pull the container docker pull ns1labs/pktvisor Or use ns1labs/pktvisor:latest-develop to get the latest development version. Start the collector agent docker run --net=host -d ns1labs/pktvisor pktvisord eth0 This will start in the background and stay running. Note that the final two arguments select pktvisord agent and the eth0 ethernet interface for packet capture. You may substitute eth0 for any known interface on your device. Note that this step requires Docker host networking to observe traffic outside the container, and that currently only Linux supports host networking . If the container does not stay running, check the docker logs output. Run the command-line UI docker run -it --rm --net=host ns1labs/pktvisor pktvisor-cli After the agent is running, you can observe results locally with the included command-line UI. This command will run the UI ( pktvisor-cli ) in the foreground and exit after pressing Ctrl+C . It connects to the running agent locally using the built-in REST API. Linux Static Binary (AppImage, x86_64) \u00b6 You may also use the Linux all-in-one binary, built with AppImage , which is available for download on the Releases page . It is designed to work on all modern Linux distributions and does not require installation or any other dependencies. curl -L http://pktvisor.com/download -o pktvisor-x86_64.AppImage chmod +x pktvisor-x86_64.AppImage ./pktvisor-x86_64.AppImage pktvisord -h For example, to run the agent on ethernet interface eth0 : ./pktvisor-x86_64.AppImage pktvisord eth0 The AppImage contains the collector agent ( pktvisord ), the command-line UI ( pktvisor-cli ), and the pcap and dnstap file analyzer ( pktvisor-reader ). You can specify which tool to run by passing it as the first argument. For example, to visualize the running agent started above with the pktvisor command-line UI: ./pktvisor-x86_64.AppImage pktvisor-cli When running the AppImage version of the agent, you may want to use the -d argument to daemonize (run in the background), and either the --log-file or --syslog argument to record logs. Also see the Advanced Agent Example . Linux Static Binaries (Stand Alone, x86_64) \u00b6 Finally, pktvisor also provides statically linked, dependency-free Linux binaries for each individual pktvisor tool ( pktvisord , pktvisor-cli , and pktvisor-reader ). These are the smallest, most compact versions of the binaries. pktvisord : curl -L http://pktvisor.com/download/pktvisord -o pktvisord-x86_64 chmod +x pktvisord-x86_64 ./pktvisord-x86_64 -h pktvisor-cli : curl -L http://pktvisor.com/download/cli -o pktvisor-cli-x86_64 chmod +x pktvisor-cli-x86_64 ./pktvisor-cli-x86_64 -h pktvisor-reader : curl -L http://pktvisor.com/download/reader -o pktvisor-reader-x86_64 chmod +x pktvisor-reader-x86_64 ./pktvisor-reader-x86_64 -h Other Platforms \u00b6 We are working on support for additional operating systems, CPU architectures, and packaging systems. If you do not see your binary available, please see the Build section to build your own. If you have a preferred installation method you would like to see supported, please create an issue .","title":"Installation"},{"location":"install/#installation","text":"","title":"Installation"},{"location":"install/#docker","text":"Get started quickly with pktvisor via the public Docker image . The image contains the collector agent ( pktvisord ), the command-line UI ( pktvisor-cli ), and the pcap and dnstap file analyzer ( pktvisor-reader ). You will specify which tool to operate when running the container. Pull the container docker pull ns1labs/pktvisor Or use ns1labs/pktvisor:latest-develop to get the latest development version. Start the collector agent docker run --net=host -d ns1labs/pktvisor pktvisord eth0 This will start in the background and stay running. Note that the final two arguments select pktvisord agent and the eth0 ethernet interface for packet capture. You may substitute eth0 for any known interface on your device. Note that this step requires Docker host networking to observe traffic outside the container, and that currently only Linux supports host networking . If the container does not stay running, check the docker logs output. Run the command-line UI docker run -it --rm --net=host ns1labs/pktvisor pktvisor-cli After the agent is running, you can observe results locally with the included command-line UI. This command will run the UI ( pktvisor-cli ) in the foreground and exit after pressing Ctrl+C . It connects to the running agent locally using the built-in REST API.","title":"Docker"},{"location":"install/#linux-static-binary-appimage-x86_64","text":"You may also use the Linux all-in-one binary, built with AppImage , which is available for download on the Releases page . It is designed to work on all modern Linux distributions and does not require installation or any other dependencies. curl -L http://pktvisor.com/download -o pktvisor-x86_64.AppImage chmod +x pktvisor-x86_64.AppImage ./pktvisor-x86_64.AppImage pktvisord -h For example, to run the agent on ethernet interface eth0 : ./pktvisor-x86_64.AppImage pktvisord eth0 The AppImage contains the collector agent ( pktvisord ), the command-line UI ( pktvisor-cli ), and the pcap and dnstap file analyzer ( pktvisor-reader ). You can specify which tool to run by passing it as the first argument. For example, to visualize the running agent started above with the pktvisor command-line UI: ./pktvisor-x86_64.AppImage pktvisor-cli When running the AppImage version of the agent, you may want to use the -d argument to daemonize (run in the background), and either the --log-file or --syslog argument to record logs. Also see the Advanced Agent Example .","title":"Linux Static Binary (AppImage, x86_64)"},{"location":"install/#linux-static-binaries-stand-alone-x86_64","text":"Finally, pktvisor also provides statically linked, dependency-free Linux binaries for each individual pktvisor tool ( pktvisord , pktvisor-cli , and pktvisor-reader ). These are the smallest, most compact versions of the binaries. pktvisord : curl -L http://pktvisor.com/download/pktvisord -o pktvisord-x86_64 chmod +x pktvisord-x86_64 ./pktvisord-x86_64 -h pktvisor-cli : curl -L http://pktvisor.com/download/cli -o pktvisor-cli-x86_64 chmod +x pktvisor-cli-x86_64 ./pktvisor-cli-x86_64 -h pktvisor-reader : curl -L http://pktvisor.com/download/reader -o pktvisor-reader-x86_64 chmod +x pktvisor-reader-x86_64 ./pktvisor-reader-x86_64 -h","title":"Linux Static Binaries (Stand Alone, x86_64)"},{"location":"install/#other-platforms","text":"We are working on support for additional operating systems, CPU architectures, and packaging systems. If you do not see your binary available, please see the Build section to build your own. If you have a preferred installation method you would like to see supported, please create an issue .","title":"Other Platforms"}]}